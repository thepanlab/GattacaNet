{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pandas_plink import read_plink\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime import submodular_pick\n",
    "import random\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating arrays with optimal data structure and filling missing values with 2--> Homozygous major '''\n",
    "\n",
    "print(\"Convertion\")\n",
    "bed=bed.astype('uint8')\n",
    "print(\"Compute\")\n",
    "X=bed.compute()\n",
    "print(\"Filling Null Data\")\n",
    "X[np.isnan(X)]=2\n",
    "#validation\n",
    "print(\"Convertion\")\n",
    "bed2=bed2.astype('uint8')\n",
    "print(\"Compute\")\n",
    "X_val=bed2.compute()\n",
    "print(\"Filling Null Data\")\n",
    "X_val[np.isnan(X_val)]=2\n",
    "print(\"Convertion\")\n",
    "#test\n",
    "bed3=bed3.astype('uint8')\n",
    "print(\"Compute\")\n",
    "X_test=bed3.compute()\n",
    "print(\"Filling Null Data\")\n",
    "X_test[np.isnan(X_test)]=2\n",
    "\n",
    "''' Preparing data.shape=(individuals,SNP) '''\n",
    "\n",
    "Y=fam[\"trait\"].astype(\"int\")\n",
    "Y=Y-1\n",
    "Xdf=pd.DataFrame(X.T)\n",
    "Xdf[\"Y\"]=Y\n",
    "\n",
    "Y_val=fam2[\"trait\"].astype(\"int\")\n",
    "Y_val=Y_val-1\n",
    "Xdf_val=pd.DataFrame(X_val.T)\n",
    "Xdf_val[\"Y\"]=Y_val\n",
    "\n",
    "Y_test=fam3[\"trait\"].astype(\"int\")\n",
    "Y_test=Y_test-1\n",
    "Xdf_test=pd.DataFrame(X_test.T)\n",
    "Xdf_test[\"Y\"]=Y_test\n",
    "\n",
    "''' Getting np arrays '''\n",
    "\n",
    "x_train=Xdf.drop(['Y'],axis=1).values\n",
    "y_train=Xdf[['Y']].values\n",
    "del Xdf\n",
    "\n",
    "x_val=Xdf_val.drop(['Y'],axis=1).values\n",
    "y_val=Xdf_val[['Y']].values\n",
    "del Xdf_val\n",
    "\n",
    "x_test=Xdf_test.drop(['Y'],axis=1).values\n",
    "y_test=Xdf_test[['Y']].values\n",
    "del Xdf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating graph'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X=tf.placeholder(tf.float32,shape=(None,5273),name=\"X\")\n",
    "X_random=tf.placeholder(tf.float32,shape=(None,1),name=\"X\")\n",
    "Y=tf.placeholder(tf.float32,shape=(None,1),name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    hidden00_drop= tf.layers.dropout(X, 0.5, training=training)\n",
    "    hidden01=tf.layers.dense(hidden00_drop, 1000, name=\"hidden01\",activation=None, kernel_initializer=initializer)\n",
    "    hidden01_norm=tf.layers.batch_normalization(hidden01, training=training, momentum=0.9)\n",
    "    act_hidden01=tf.nn.leaky_relu(hidden01_norm)\n",
    "    hidden01_drop = tf.layers.dropout(act_hidden01, 0.5, training=training)\n",
    "    hidden0=tf.layers.dense(hidden01_drop, 250, name=\"hidden0\",activation=None, kernel_initializer=initializer)\n",
    "    hidden0_norm=tf.layers.batch_normalization(hidden0, training=training, momentum=0.9)\n",
    "    act_hidden0=tf.nn.leaky_relu(hidden0_norm)\n",
    "    hidden0_drop = tf.layers.dropout(act_hidden0, 0.5, training=training)\n",
    "    hidden1=tf.layers.dense(hidden0_drop, 50, name=\"hidden1\",activation=None, kernel_initializer=initializer)\n",
    "    hidden1_norm=tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "    act_hidden1=tf.nn.leaky_relu(hidden1_norm)\n",
    "    hidden1_drop = tf.layers.dropout(act_hidden1, 0.5, training=training)\n",
    "    output=tf.layers.dense(  hidden1_drop, 1, name=\"output_final\",activation=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=output)\n",
    "    weights = tf.trainable_variables()\n",
    "    loss=tf.reduce_mean(cross_entropy)\n",
    "    error=loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer =tf.train.AdamOptimizer(learning_rate=0.0001,beta1=0.9,beta2=0.999,epsilon=1e-08,use_locking=False,name='Adam')\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    predicted = tf.nn.sigmoid(output)\n",
    "    correct_pred = tf.equal(tf.round(predicted), Y)\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    _,auc = tf.metrics.auc(labels=Y,predictions=predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Restaure the trained model. No need to train!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(device_count={ \"CPU\": 44}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess, \"/work/breastcancer/clean_test/logs/preprocessed001.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Getting individuals where precision > 90%'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=sess.run(predicted,feed_dict={X:x_test,Y:y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important=np.argwhere(pred==pred[pred>0.67])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train explainer'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pre-training (scaling and preparing LIME representation space...)'''\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(x_train ,class_names=['not tumour', 'Tumor'],categorical_features = range(5273), feature_names = list(bim[\"snp\"].values), kernel_width=40, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    if len(x.shape)>1:\n",
    "         return np.array([1-sess.run(tf.nn.sigmoid(output),feed_dict={X:x})[:,0],sess.run(tf.nn.sigmoid(output),feed_dict={X:x})[:,0]]).T\n",
    "    else:\n",
    "        return np.array([[1-sess.run(tf.nn.sigmoid(output),feed_dict={X:np.expand_dims(x,axis=1).T})[0,0],sess.run(tf.nn.sigmoid(output),feed_dict={X:np.expand_dims(x,axis=1).T})[0,0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''submodular explanation of testing set'''\n",
    "pick=submodular_pick.SubmodularPick(explainer, x_test[important], predict_fn, sample_size=553, num_features=41, num_exps_desired=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Getting average contribution values over explanations'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contribution_values_per_explanation=pd.DataFrame([dict(this.as_list()) for this in pick.explanations])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_values_per_explanation.to_csv(paht_logs+\"lime_contributions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_conributions=contribution_values_per_explanation.fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,5))\n",
    "\n",
    "ax.plot(average_conributions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
