{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN evaluation across different sizes for a given p-value threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pandas_plink import read_plink\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "\n",
    "import random\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Minibatch function'''\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parameters for experiment '''\n",
    "threshold=\"0.01\"\n",
    "path_logs=\"/work/breastcancer/clean_test/logs/\"\n",
    "path_to_files=\"/work/breastcancer/clean_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' getting bim,fam,bed for training,validation and test sets '''\n",
    "(bim, fam, bed)=read_plink(path_to_files+\"train/sig\"+threshold)\n",
    "(bim2, fam2, bed2)=read_plink(path_to_files+\"validation/val\"+threshold)\n",
    "(bim3, fam3, bed3)=read_plink(path_to_files+\"test/test\"+threshold)\n",
    "\n",
    "path_logs=\"/work/breastcancer/clean_test/logs/\"\n",
    "\n",
    "print(bim)\n",
    "\n",
    "print(fam)\n",
    "\n",
    "''' Creating arrays with optimal data structure and filling missing values with 2--> Homozygous major '''\n",
    "print(\"Convertion\")\n",
    "bed=bed.astype('uint8')\n",
    "print(\"Compute\")\n",
    "X=bed.compute()\n",
    "print(\"Filling Null Data\")\n",
    "X[np.isnan(X)]=2\n",
    "#validation\n",
    "print(\"Convertion\")\n",
    "bed2=bed2.astype('uint8')\n",
    "print(\"Compute\")\n",
    "X_val=bed2.compute()\n",
    "print(\"Filling Null Data\")\n",
    "X_val[np.isnan(X_val)]=2\n",
    "#test\n",
    "print(\"Convertion\")\n",
    "bed3=bed3.astype('uint8')\n",
    "print(\"Compute\")\n",
    "X_test=bed3.compute()\n",
    "print(\"Filling Null Data\")\n",
    "X_test[np.isnan(X_test)]=2\n",
    "\n",
    "''' Preparing data.shape=(individuals,SNP) '''\n",
    "#train\n",
    "Y=fam[\"trait\"].astype(\"int\")\n",
    "Y=Y-1\n",
    "Xdf=pd.DataFrame(X.T)\n",
    "Xdf[\"Y\"]=Y\n",
    "\n",
    "#validation\n",
    "Y_val=fam2[\"trait\"].astype(\"int\")\n",
    "Y_val=Y_val-1\n",
    "Xdf_val=pd.DataFrame(X_val.T)\n",
    "Xdf_val[\"Y\"]=Y_val\n",
    "\n",
    "#test\n",
    "Y_test=fam3[\"trait\"].astype(\"int\")\n",
    "Y_test=Y_test-1\n",
    "Xdf_test=pd.DataFrame(X_test.T)\n",
    "Xdf_test[\"Y\"]=Y_test\n",
    "\n",
    "''' Getting np arrays '''\n",
    "x_train=Xdf.drop(['Y'],axis=1).values\n",
    "y_train=Xdf[['Y']].values\n",
    "\n",
    "x_val=Xdf_val.drop(['Y'],axis=1).values\n",
    "y_val=Xdf_val[['Y']].values\n",
    "\n",
    "x_test=Xdf_test.drop(['Y'],axis=1).values\n",
    "y_test=Xdf_test[['Y']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MODEL '''\n",
    "\n",
    "''' Inputs tensors '''\n",
    "tf.reset_default_graph()\n",
    "X=tf.placeholder(tf.float32,shape=(None,x_train.shape[1]),name=\"X\")\n",
    "Y=tf.placeholder(tf.float32,shape=(None,1),name=\"Y\")\n",
    "\n",
    "''' DNN with dropout rate=0.5 and Batch Norm'''\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    hidden00_drop= tf.layers.dropout(X, 0.5, training=training)\n",
    "    hidden01=tf.layers.dense(hidden00_drop, 1000, name=\"hidden01\",activation=None, kernel_initializer=initializer)\n",
    "    hidden01_norm=tf.layers.batch_normalization(hidden01, training=training, momentum=0.9)\n",
    "    act_hidden01=tf.nn.leaky_relu(hidden01_norm)\n",
    "    hidden01_drop = tf.layers.dropout(act_hidden01, 0.5, training=training)\n",
    "    hidden0=tf.layers.dense(hidden01_drop, 250, name=\"hidden0\",activation=None, kernel_initializer=initializer)\n",
    "    hidden0_norm=tf.layers.batch_normalization(hidden0, training=training, momentum=0.9)\n",
    "    act_hidden0=tf.nn.leaky_relu(hidden0_norm)\n",
    "    hidden0_drop = tf.layers.dropout(act_hidden0, 0.5, training=training)\n",
    "    hidden1=tf.layers.dense(hidden0_drop, 50, name=\"hidden1\",activation=None, kernel_initializer=initializer)\n",
    "    hidden1_norm=tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "    act_hidden1=tf.nn.leaky_relu(hidden1_norm)\n",
    "    hidden1_drop = tf.layers.dropout(act_hidden1, 0.5, training=training)\n",
    "    hidden1_norm=tf.layers.batch_normalization(hidden1_drop, training=training, momentum=0.9)\n",
    "    output=tf.layers.dense(  hidden1_norm, 1, name=\"output_final\",activation=None)\n",
    "\n",
    "''' Log-Loss '''\n",
    "with tf.name_scope(\"loss\"):\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=output)\n",
    "    weights = tf.trainable_variables()\n",
    "    loss=tf.reduce_mean(cross_entropy)\n",
    "    error=loss\n",
    "\n",
    "''' Adam Optimizer '''\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer =tf.train.AdamOptimizer(learning_rate=0.0001,beta1=0.9,beta2=0.999,epsilon=1e-08,use_locking=False,name='Adam')\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(error)\n",
    "\n",
    "''' Metrics '''\n",
    "with tf.name_scope(\"eval\"):\n",
    "    predicted = tf.nn.sigmoid(output)\n",
    "    correct_pred = tf.equal(tf.round(predicted), Y)\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    _,auc = tf.metrics.auc(labels=Y,predictions=predicted)\n",
    "\n",
    "saver=tf.train.Saver(max_to_keep=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train models with different size and record the best per size'''\n",
    "open('/work/breastcancer/Test_preprocessed_filter7.txt', 'w')\n",
    "sizes=[10000,20000,30000,x_train.shape[0]]\n",
    "best_val_size=[]\n",
    "for size in sizes:\n",
    "    best_auc=0\n",
    "    init=tf.global_variables_initializer()\n",
    "    loc=tf.local_variables_initializer()\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(device_count={ \"CPU\": 44}))\n",
    "    init.run()\n",
    "    loc.run()\n",
    "    auc_tab=[]\n",
    "    accuracy_tab=[]\n",
    "    loss_tab=[]\n",
    "    epoch_tab=[]\n",
    "    auc_tab_val=[]\n",
    "    accuracy_tab_val=[]\n",
    "    loss_tab_val=[]\n",
    "    #Training\n",
    "    for epoch in range(200):\n",
    "        iteration=0\n",
    "        batch_size=512\n",
    "        for x_batch,y_batch in shuffle_batch(x_train[0:size,:], y_train[0:size,:], batch_size):\n",
    "            sess.run(training_op,feed_dict={X:x_batch,Y:y_batch,training:True})\n",
    "            print(\"%d ITERATION:%d/%d \"%(epoch,iteration,len(x_train[0:size,:])//batch_size),end='\\r')\n",
    "            iteration+=1\n",
    "\n",
    "        loc.run()\n",
    "        loss_train,acc_train,auc_train=sess.run([loss,acc,auc],feed_dict={X:x_batch,Y:y_batch,training:False})\n",
    "        print(epoch,\"Train accuracy:\",acc_train,\"Loss:\",loss_train,\"AUC:\",auc_train)\n",
    "        auc_tab.append(auc_train)\n",
    "        accuracy_tab.append(acc_train)\n",
    "        epoch_tab.append(epoch)\n",
    "        loss_tab.append(loss_train)\n",
    "        #validation\n",
    "        loc.run()\n",
    "        loss_val,acc_val,auc_val=sess.run([loss,acc,auc],feed_dict={X:x_val,Y:y_val,training:False})\n",
    "        auc_tab_val.append(auc_val)\n",
    "        accuracy_tab_val.append(acc_val)\n",
    "        loss_tab_val.append(loss_val)\n",
    "        if auc_val>best_auc:\n",
    "            save_path = saver.save(sess,path_logs+\"preprocessed\"+threshold+\"_data_\"+size+\".ckpt\")\n",
    "            best_auc=auc_val\n",
    "        print(epoch,\"Validation accuracy:\",acc_val,\"Loss:\",loss_val,\"AUC:\",auc_val)\n",
    "        print(\"\\n\")\n",
    "    sess.close()\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(device_count={ \"CPU\": 44}))\n",
    "    init.run()\n",
    "    loc.run()\n",
    "    #Test score for the best model for AUC score on validation set. This final test is made on the test set \n",
    "    saver.restore(sess, path_logs+\"preprocessed\"+threshold+\"_data_\"+size+\".ckpt\")\n",
    "    auc_test=sess.run(auc,feed_dict={X:x_test,Y:y_test,training:False})\n",
    "    print(best_auc,auc_test)\n",
    "    best_val_size.append([best_auc,auc_test])\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save Results'''\n",
    "np.savetxt(path_logs+\"best_value_test_auc.csv\", np.array(best_val_size), delimiter=\",\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
